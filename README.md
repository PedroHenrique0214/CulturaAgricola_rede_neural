# Cultura Agricola usando rede neural
Predi√ß√£o de 'crops' (culturas agr√≠colas) para encontrar a melhor op√ß√£o para determinado solo.

### 01. Introdu√ß√£o

Vamos subor que tenhamos uma s√©rie de informa√ß√µes coletadas sobre um solo, e queremos descobrir qual seria a planta√ß√£o adequada para se plantar nesse solo com base em informa√ß√µes de outros produtores. Podemos ent√£o utilizar um modelo de machine learning para nos dizer qual seria a melhor op√ß√£o de planta√ß√£o. 

Este √© um problema de classifica√ß√£o multiclasse, com mais de duas sa√≠das poss√≠veis. Vamos criar uma rede neural para tentar predizer qual √© a melhor op√ß√£o de planta√ß√£o com base em nosso data set coletado na Kagle. A constru√ß√£o da rede neural se dar√° atrav√©s do TensorFlow, e poderemos observar como utilizar essa poderosa ferramenta de rede profunda de maneira r√°pida para solucionar um problema que pode ocorrer na decis√£o do pequeno agropecu√°rio ao se decidir o que plantar no solo.

dataset: https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset

### 02. Conhecendo o dataset
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Nitrogen</th>
      <th>Phosphorus</th>
      <th>Potassium</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>pH_Value</th>
      <th>Rainfall</th>
      <th>Crop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>90</td>
      <td>42</td>
      <td>43</td>
      <td>20.879744</td>
      <td>82.002744</td>
      <td>6.502985</td>
      <td>202.935536</td>
      <td>Rice</td>
    </tr>
    <tr>
      <th>1</th>
      <td>85</td>
      <td>58</td>
      <td>41</td>
      <td>21.770462</td>
      <td>80.319644</td>
      <td>7.038096</td>
      <td>226.655537</td>
      <td>Rice</td>
    </tr>
    <tr>
      <th>2</th>
      <td>60</td>
      <td>55</td>
      <td>44</td>
      <td>23.004459</td>
      <td>82.320763</td>
      <td>7.840207</td>
      <td>263.964248</td>
      <td>Rice</td>
    </tr>
    <tr>
      <th>3</th>
      <td>74</td>
      <td>35</td>
      <td>40</td>
      <td>26.491096</td>
      <td>80.158363</td>
      <td>6.980401</td>
      <td>242.864034</td>
      <td>Rice</td>
    </tr>
    <tr>
      <th>4</th>
      <td>78</td>
      <td>42</td>
      <td>42</td>
      <td>20.130175</td>
      <td>81.604873</td>
      <td>7.628473</td>
      <td>262.717340</td>
      <td>Rice</td>
    </tr>
  </tbody>
</table>
</div>

**Temos algumas informa√ß√µes sobre o solo**
* Nitrog√™nio;
* F√≥sforo;
* Pot√°ssio;
* Temperatura;
* Humidade;
* pH;
* Pluviosidade.

  ### 03. Visualizando nossos dados
  
![image](https://github.com/PedroHenrique0214/CulturaAgricola_rede_neural/assets/155765414/f0cd4edf-2d34-4a3e-bbac-179cf3786e0e)

A an√°lise dos boxplots revela a presen√ßa de alguns outliers em nosso conjunto de dados. No entanto, √© crucial considerar o contexto do nosso problema e examinar mais detalhadamente os dados coletados. Esses valores s√£o consistentes com padr√µes observados em solos destinados √† produ√ß√£o agr√≠cola. Por exemplo, valores de pH abaixo de 4 ou acima de 10, embora raros, n√£o s√£o imposs√≠veis e, portanto, n√£o devem ser descartados automaticamente como outliers.

Para solucionar problemas relacionados a dados, √© fundamental compreender o contexto em que esses dados foram coletados. Esse entendimento √© essencial para a continuidade das nossas an√°lises. Sem esse conhecimento contextual, uma pessoa pode interpretar erroneamente valores at√≠picos, como concentra√ß√µes de pot√°ssio incomuns no solo, podendo descart√°-los indevidamente ou presumir que houve algum erro na coleta dos dados.
  
![image](https://github.com/PedroHenrique0214/CulturaAgricola_rede_neural/assets/155765414/4a1a0b96-7814-42eb-94fe-465477057117)

Analisando a distribui√ß√£o dos nosso dados podemos observar algumas coisas:
* A distribui√ß√£o normal na temperatura e no ph do solo j√° eram caracter√≠sticas esperadas para essea atributos. 
* Muitos atributos aparentam ter uma bimodalidade na distribui√ß√£o, o que indica duas condi√ß√µes distintas para produ√ß√£o agr√≠cola. Por exemplo, indica√ß√µes de pot√°ssio entre 15~50 e uma contagem em ~200 indica que tem produtos que podem se beneficiar de valores extremos de concentra√ß√£o de pot√°ssio no solo. Isso pode ser observado tamb√©m em umidade e f√≥sforo.
* Vemos claramento a presen√ßa de outliers, s√£o bastantes visuais. Mas novamento, isso n√£o significa que s√£o valores mal coletados, √© necess√°rio saber a realidade da produ√ß√£o agr√≠cula e como nossos dados foram coletados.


**Vamos a m√©dia de nossas features para cada sa√≠da (planta√ß√£o) poss√≠vel.**
![image](https://github.com/PedroHenrique0214/CulturaAgricola_rede_neural/assets/155765414/e47a9815-b14d-42ee-9fb5-2d6cc666e196)

Podemos visualizar quais s√£o os valores ideais para cada tipo de produ√ß√£o com base em nossos dados. Com esses valores, nosso modelo ser√° capaz de recomendar a melhor cultura a ser plantada, dependendo dos valores coletados do solo.

Observamos que diferentes culturas podem ter caracter√≠sticas recomendadas semelhantes, apresentando valores indicados similares para alguns atributos do solo. No entanto, vamos desenvolver um modelo capaz de distinguir esses padr√µes similares e encontrar solu√ß√µes espec√≠ficas para cada caso.

Um produtor agr√≠cola poderia analisar essas tabelas por dias para determinar o melhor curso de a√ß√£o para sua produ√ß√£o. Contudo, com o modelo que iremos construir, nossa rede neural fornecer√° essas respostas de forma autom√°tica, r√°pida e eficiente. Nosso modelo poderia obter muitas outras sa√≠das e informa√ß√µes para aprimorar nosso modelo e aplic√°-lo na pr√°tica em uma grande escala, mas, esta nossa abordagem atual j√° permitir√° realizar testes e auxiliar pequenos empreendedores que n√£o disp√µem de todos os recursos necess√°rios para escolher a melhor op√ß√£o. 

### 04. Fazendo nosso modelo de Rede Neural

```python
# Criando o modelo
modelo = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(22, activation='softmax')
])

# Compilando o modelo
modelo.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
               optimizer=tf.keras.optimizers.Adam(),
               metrics=['accuracy'])

# 'Fit' o modelo
history = modelo.fit(X_train,
           tf.one_hot(y_train, depth=22),
           epochs=50,
           validation_data=(X_test, tf.one_hot(y_test, depth=22)))
```
![image](https://github.com/PedroHenrique0214/CulturaAgricola_rede_neural/assets/155765414/d3c6dd59-d5b9-481f-b1bb-4672ce8a581d)

* *Fazendo nosso modelo normalizado*
```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

# Ajustando nosso modelo de treino para normalizar
X_train_norm = scaler.fit_transform(X_train)
# Normalizando tamb√©m nosso teste
X_test_norm = scaler.fit_transform(X_test)

# Criando o modelo
modelo_norm = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(22, activation='softmax')
])

# Compilando o modelo
modelo_norm.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
               optimizer=tf.keras.optimizers.Adam(),
               metrics=['accuracy'])

# 'Fit' o modelo
history_norm = modelo_norm.fit(X_train_norm,
           tf.one_hot(y_train, depth=22),
           epochs=50,
           validation_data=(X_test_norm, tf.one_hot(y_test, depth=22)))
```

Nosso modelo normalizado apresentou melhor acur√°cia do que nosso modelo sem nenhuma transforma√ß√£o dos dados. Vamos prosseguir com nossos dados normalizados. Modelos de rede neural tendem a operar melhor com os dados tratados.

![image](https://github.com/PedroHenrique0214/CulturaAgricola_rede_neural/assets/155765414/549a3624-3ac3-4dbf-9420-4a42a1ff69be)

### 05. Valida√ß√£o do nosso modelo

[1m21/21[0m [32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m[37m[0m [1m0s[0m 576us/step
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        33
           1       1.00      1.00      1.00        33
           2       1.00      1.00      1.00        27
           3       1.00      1.00      1.00        36
           4       0.97      1.00      0.99        36
           5       0.97      0.85      0.90        33
           6       0.86      1.00      0.93        19
           7       1.00      1.00      1.00        28
           8       0.95      0.66      0.78        32
           9       1.00      1.00      1.00        41
          10       0.96      1.00      0.98        25
          11       0.84      0.90      0.87        29
          12       1.00      1.00      1.00        23
          13       1.00      0.97      0.98        29
          14       1.00      1.00      1.00        25
          15       1.00      0.89      0.94        36
          16       1.00      0.96      0.98        26
          17       0.97      1.00      0.99        37
          18       1.00      1.00      1.00        27
          19       1.00      1.00      1.00        30
          20       0.75      0.96      0.84        28
          21       0.87      1.00      0.93        27

    accuracy                           0.96       660
   macro avg       0.96      0.96      0.96       660
weighted avg       0.96      0.96      0.96       660

![image](https://github.com/PedroHenrique0214/CulturaAgricola_rede_neural/assets/155765414/8e222d8b-839a-4eac-b1c5-da064dcb6671)
